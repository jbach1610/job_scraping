{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish importing packages\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import time\n",
    "\n",
    "# Store data as a csv file written out\n",
    "from csv import writer\n",
    "from datetime import datetime\n",
    "\n",
    "# Random integer for more realistic timing for clicks, buttons and searches during scraping\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "# Dataframe stuff\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from seleniumbase import Driver\n",
    "from sqlalchemy import create_engine,exc\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "# Manages Binaries needed for WebDriver without installing anything directly\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "print(\"- Finish importing packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish initializing a driver\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# job_= input(\"What position do you want to search?\").replace(' ','+')\n",
    "# location= input(\"What location do you target?\").replace(' ','+')\n",
    "job_ = \"Financial+Analyst\"\n",
    "location = \"united+states\"\n",
    "\n",
    "\n",
    "job_lst = []\n",
    "job_description_list = []\n",
    "urls = []\n",
    "skills_list = []\n",
    "salaries = []\n",
    "job_models = []\n",
    "target_url = \"https://www.indeed.com/jobs?q={}&l={}&sc=0kf%3Aexplvl%28ENTRY_LEVEL%29%3B&start={}\"\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"user-data-dir=C:\\\\Users\\\\Hien Bach\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "options.add_argument(\"--profile-directory=Profile 3\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "options.add_argument(\"--remote-debugging-pipe\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "sleep(randint(2, 4))\n",
    "\n",
    "# define number of available jobs\n",
    "driver.get(target_url.format(job_, location, 0))\n",
    "print(\"- Finish initializing a driver\")\n",
    "sleep(randint(2, 4))\n",
    "\n",
    "# WebDriverWait(driver, 20).until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR,\"iframe[title='Widget containing a Cloudflare security challenge']\")))\n",
    "# WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"label.ctp-checkbox-label\"))).click()\n",
    "\n",
    "src = driver.page_source\n",
    "soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "num = soup.find(\"div\", {\"class\": \"jobsearch-JobCountAndSortPane-jobCount\"}).find(\"span\").get_text()\n",
    "num_of_pgs = int(num.split(\" \")[0].replace(',','')) // 15\n",
    "sleep(randint(2, 4))\n",
    "\n",
    "# start scraping\n",
    "for i in range(0, num_of_pgs + 1):\n",
    "    driver.get(target_url.format(job_, location, i * 10))\n",
    "    src = driver.page_source\n",
    "    soup1 = BeautifulSoup(src, \"html.parser\")\n",
    "    jobs = soup1.find_all(\"div\", class_=\"job_seen_beacon\")\n",
    "\n",
    "    for jj in jobs:\n",
    "\n",
    "        job_title = jj.find(\"h2\", class_=\"jobTitle\")\n",
    "        job_key = job_title.find(\"a\").get(\"data-jk\")\n",
    "        lo_co = jj.find(\"div\", class_=\"company_location\")\n",
    "        com = (\n",
    "            lo_co.find(\"div\", {\"data-testid\": \"timing-attribute\"})\n",
    "            .find(\"span\", {\"data-testid\": \"company-name\"})\n",
    "            .get_text()\n",
    "            .strip()\n",
    "        )\n",
    "        lo = (\n",
    "            lo_co.find(\"div\", {\"data-testid\": \"timing-attribute\"})\n",
    "            .find(\"div\", {\"data-testid\": \"text-location\"})\n",
    "            .get_text()\n",
    "            .strip()\n",
    "        )\n",
    "        state = lo.split(\",\")[-1].strip()[0:2]\n",
    "        link_temp = job_title.find(\"a\").get(\"href\")\n",
    "        link = \"https://www.indeed.com/\" + link_temp\n",
    "        job_lst.append([job_title.get_text().strip(), job_key, com, lo, state, link])\n",
    "        urls.append(link)\n",
    "\n",
    "    for url in urls:\n",
    "\n",
    "        driver.get(url)\n",
    "        sleep(randint(2, 4))\n",
    "        src = driver.page_source\n",
    "        soup2 = BeautifulSoup(src, \"html.parser\")\n",
    "\n",
    "        try:\n",
    "            job_description_list.append(soup2.find(\"div\", id=\"jobDescriptionText\").get_text().strip())\n",
    "        except Exception:\n",
    "            job_description_list.append(None)\n",
    "\n",
    "        try:\n",
    "            salaries.append(soup2.find(\"div\", id=\"salaryInfoAndJobType\").find(\"span\", class_=\"css-19j1a75 eu4oa1w0\").get_text().strip())\n",
    "        except Exception:\n",
    "            salaries.append(None)\n",
    "\n",
    "        try:\n",
    "            job_models.append(soup2.find(\"div\", class_=\"css-6z8o9s eu4oa1w0\").get_text().strip())\n",
    "        except Exception:\n",
    "            job_models.append(None)\n",
    "        \n",
    "        try:\n",
    "            skills_block = soup2.find(\"div\", attrs={\"aria-label\":\"Skills\"})\n",
    "            skills_section = skills_block.find(\"ul\", class_=\"js-match-insights-provider-1o7r14h eu4oa1w0\")\n",
    "            try:\n",
    "                show_more = skills_section.find(\"li\", class_=\"js-match-insights-provider-6oegoj eu4oa1w0\")\n",
    "                if show_more.get_text() == '+ show more':\n",
    "\n",
    "                    show_more_button = driver.find_element(By.XPATH, \"//button [contains( text(), '+ show more')]\")\n",
    "\n",
    "                    # show_more_button = driver.find_element(By.XPATH, '//*[@id=\"js-match-insights-provider\"]/div/div/div/div[1]/div[2]/div/div/ul/li[4]/button')\n",
    "                    actions = ActionChains(driver)\n",
    "                    actions.move_to_element(show_more_button).perform()\n",
    "                    sleep(5)\n",
    "                    \n",
    "                    show_more_button.click()\n",
    "                    sleep(5)\n",
    "\n",
    "                    src = driver.page_source\n",
    "                    soup1 = BeautifulSoup(src, \"html.parser\")\n",
    "                    skills_section_temp = soup1.find(\"ul\", class_=\"js-match-insights-provider-1o7r14h eu4oa1w0\")\n",
    "                    skills_cards_temp = skills_section_temp.find_all(\"li\", class_=\"js-match-insights-provider-10zb82q eu4oa1w0\")\n",
    "                    skills_temp = [s.get_text().strip() for s in skills_cards_temp]\n",
    "                    skills = ', '.join(skills_temp)\n",
    "                    skills_list.append(skills)\n",
    "            except Exception:\n",
    "                skills_cards = skills_section.find_all(\"div\", class_=\"js-match-insights-provider-g6kqeb ecydgvn0\")\n",
    "                skills_temp = [s.get_text().strip() for s in skills_cards]\n",
    "                skills = ', '.join(skills_temp)\n",
    "                skills_list.append(skills)\n",
    "        except Exception:       \n",
    "            skills_list.append(None)\n",
    "        skills_temp = []\n",
    "        \n",
    "    urls = []\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "end = time.time()\n",
    "print(end - start, \"seconds to complete Query!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "job_dict= {\n",
    "    \"ID\": [],\n",
    "    \"Title\": [],\n",
    "    \"Company\": [],\n",
    "    \"Location\": [],\n",
    "    \"State\": [],\n",
    "    \"Salary\": [],\n",
    "    \"Type\": [],\n",
    "    \"Skills\": [],\n",
    "    \"Description\": [],\n",
    "    \"Link\": [],\n",
    "    \"Job Board\": [],\n",
    "}\n",
    "for i in range(0, len(job_lst)):\n",
    "    job_dict[\"Title\"].append(job_lst[i][0])\n",
    "    job_dict[\"ID\"].append(job_lst[i][1])\n",
    "    job_dict[\"Company\"].append(job_lst[i][2])\n",
    "    job_dict[\"Location\"].append(job_lst[i][3])\n",
    "    job_dict[\"State\"].append(job_lst[i][4])\n",
    "    job_dict[\"Link\"].append(job_lst[i][5])\n",
    "    job_dict[\"Salary\"].append(salaries[i])\n",
    "    job_dict[\"Type\"].append(job_models[i])\n",
    "    job_dict[\"Skills\"].append(skills_list[i])\n",
    "    job_dict[\"Description\"].append(job_description_list[i])\n",
    "    job_dict[\"Job Board\"].append(\"Indeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(job_dict)\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:myhien2004@localhost:3306/sample\", echo=False)\n",
    "connection = engine.connect()\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        df.iloc[i:i+1].to_sql(\"job_scrape\", con=connection, if_exists=\"append\", index=False)\n",
    "    except exc.IntegrityError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(job_dict)\n",
    "# engine = create_engine(\"mysql+mysqlconnector://root:myhien2004@localhost:3306/sample\", echo=False)\n",
    "# connection = engine.connect()\n",
    "# df.to_sql(\"job_scrape_temp\", con=connection, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict = {\n",
    "#     'id' : [1,2,1,3,2,5,7,9],\n",
    "#     'stu': ['a','b','a','c','b','e','g','i']\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>State</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Type</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "      <th>Job Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1f4f2add687bc7f2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Quest Global</td>\n",
       "      <td>Rockford, IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Data science, Data collection, Data analytics,...</td>\n",
       "      <td>Quest Global is an organization at the forefro...</td>\n",
       "      <td>https://www.indeed.com//rc/clk?jk=1f4f2add687b...</td>\n",
       "      <td>Indeed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID         Title       Company      Location State Salary  \\\n",
       "0  1f4f2add687bc7f2  Data Analyst  Quest Global  Rockford, IL    IL   None   \n",
       "\n",
       "  Type                                             Skills  \\\n",
       "0       Data science, Data collection, Data analytics,...   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Quest Global is an organization at the forefro...   \n",
       "\n",
       "                                                Link Job Board  \n",
       "0  https://www.indeed.com//rc/clk?jk=1f4f2add687b...    Indeed  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(job_dict)\n",
    "df.head()\n",
    "# print(len(job_dict))\n",
    "# for key in job_lst:\n",
    "#     print(key[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# job_= input(\"What position do you want to search?\").replace(' ','+')\n",
    "# location= input(\"What location do you target?\").replace(' ','+')\n",
    "job_ = \"portfolio+management\"\n",
    "location = \"united+states\"\n",
    "\n",
    "\n",
    "job_lst = []\n",
    "job_description_list = []\n",
    "urls = []\n",
    "skills_list = []\n",
    "salaries = []\n",
    "job_models = []\n",
    "key_lst = set()\n",
    "target_url = \"https://www.indeed.com/jobs?q={}&l={}&sc=0kf%3Aexplvl%28ENTRY_LEVEL%29%3B&start={}\"\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"user-data-dir=C:\\\\Users\\\\Hien Bach\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "options.add_argument(\"--profile-directory=Profile 3\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "options.add_argument(\"--remote-debugging-pipe\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "sleep(randint(2, 4))\n",
    "\n",
    "# define number of available jobs\n",
    "driver.get(target_url.format(job_, location, 0))\n",
    "print(\"- Finish initializing a driver\")\n",
    "sleep(randint(2, 4))\n",
    "\n",
    "src = driver.page_source\n",
    "soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "num = soup.find(\"div\", {\"class\": \"jobsearch-JobCountAndSortPane-jobCount\"}).find(\"span\").get_text()\n",
    "num_of_pgs = int(num.split(\" \")[0].replace(',','')) // 15\n",
    "sleep(randint(2, 4))\n",
    "\n",
    "# start scraping\n",
    "for i in range(0, num_of_pgs + 1):\n",
    "    driver.get(target_url.format(job_, location, i * 10))\n",
    "    src = driver.page_source\n",
    "    soup1 = BeautifulSoup(src, \"html.parser\")\n",
    "    jobs = soup1.find_all(\"div\", class_=\"job_seen_beacon\")\n",
    "\n",
    "    for jj in jobs:\n",
    "\n",
    "        job_title = jj.find(\"h2\", class_=\"jobTitle\")\n",
    "        job_key = job_title.find(\"a\").get(\"data-jk\")\n",
    "        if job_key not in key_lst:\n",
    "            key_lst.add(job_key)\n",
    "            lo_co = jj.find(\"div\", class_=\"company_location\")\n",
    "            com = (\n",
    "                lo_co.find(\"div\", {\"data-testid\": \"timing-attribute\"})\n",
    "                .find(\"span\", {\"data-testid\": \"company-name\"})\n",
    "                .get_text()\n",
    "                .strip()\n",
    "            )\n",
    "            lo = (\n",
    "                lo_co.find(\"div\", {\"data-testid\": \"timing-attribute\"})\n",
    "                .find(\"div\", {\"data-testid\": \"text-location\"})\n",
    "                .get_text()\n",
    "                .strip()\n",
    "            )\n",
    "            state = lo.split(\",\")[-1].strip()[0:2]\n",
    "            link_temp = job_title.find(\"a\").get(\"href\")\n",
    "            link = \"https://www.indeed.com/\" + link_temp\n",
    "            job_lst.append([job_title.get_text().strip(), job_key, com, lo, state, link])\n",
    "            urls.append(link)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "    for url in urls:\n",
    "\n",
    "        driver.get(url)\n",
    "        sleep(randint(2, 4))\n",
    "        src = driver.page_source\n",
    "        soup2 = BeautifulSoup(src, \"html.parser\")\n",
    "\n",
    "        try:\n",
    "            job_description_list.append(soup2.find(\"div\", id=\"jobDescriptionText\").get_text().strip())\n",
    "        except Exception:\n",
    "            job_description_list.append(None)\n",
    "\n",
    "        try:\n",
    "            salaries.append(soup2.find(\"div\", id=\"salaryInfoAndJobType\").find(\"span\", class_=\"css-19j1a75 eu4oa1w0\").get_text().strip())\n",
    "        except Exception:\n",
    "            salaries.append(None)\n",
    "\n",
    "        try:\n",
    "            job_models.append(soup2.find(\"div\", class_=\"css-6z8o9s eu4oa1w0\").get_text().strip())\n",
    "        except Exception:\n",
    "            job_models.append(None)\n",
    "            \n",
    "        try:\n",
    "            skills_block = soup.find(\"div\", attrs={\"aria-label\":\"Skills\"})\n",
    "            skills_section = skills_block.find(\"ul\", class_=\"js-match-insights-provider-1o7r14h eu4oa1w0\")\n",
    "            try:\n",
    "                show_more = skills_section.find(\"li\", class_=\"js-match-insights-provider-6oegoj eu4oa1w0\")\n",
    "                if show_more.get_text() == '+ show more':\n",
    "                    show_more_button = driver.find_element(By.XPATH, \"//button [contains( text(), '+ show more')]\")\n",
    "                    # show_more_button = driver.find_element(By.XPATH, '//*[@id=\"js-match-insights-provider\"]/div/div/div/div[1]/div[2]/div/div/ul/li[4]/button')\n",
    "                    actions = ActionChains(driver)\n",
    "                    actions.move_to_element(show_more_button).perform()\n",
    "                    sleep(5)\n",
    "                    \n",
    "                    show_more_button.click()\n",
    "                    sleep(5)\n",
    "\n",
    "                    src = driver.page_source\n",
    "                    soup3 = BeautifulSoup(src, \"html.parser\")\n",
    "                    skills_section_temp = soup3.find(\"ul\", class_=\"js-match-insights-provider-1o7r14h eu4oa1w0\")\n",
    "                    skills_cards_temp = skills_section_temp.find_all(\"li\", class_=\"js-match-insights-provider-10zb82q eu4oa1w0\")\n",
    "                    skills_temp = [s.get_text().strip() for s in skills_cards_temp]\n",
    "                    skills = ', '.join(skills_temp)\n",
    "                    skills_list.append(skills)\n",
    "            except Exception:\n",
    "                skills_cards = skills_section.find_all(\"div\", class_=\"js-match-insights-provider-g6kqeb ecydgvn0\")\n",
    "                skills_temp = [s.get_text().strip() for s in skills_cards]\n",
    "                skills = ', '.join(skills_temp)\n",
    "                skills_list.append(skills)\n",
    "        except Exception:\n",
    "            skills_list.append(None)\n",
    "        skills_temp = []\n",
    "        \n",
    "    urls = []\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "end = time.time()\n",
    "print(end - start, \"seconds to complete Query!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working_model: class_ = \"css-6z8o9s eu4oa1w0\" in \"div\" tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
